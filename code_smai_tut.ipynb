{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KeyurIITGN/TEMP_REP/blob/main/code_smai_tut.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9LRJCZWFWqm"
      },
      "source": [
        "# Probability Tutorial\n",
        "\n",
        "Course: Statistical Methods in AI\n",
        "\n",
        "Date: 3 February, 2025"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIx6UoApFWqu"
      },
      "source": [
        "## 0. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7IUIF8vFWqv"
      },
      "outputs": [],
      "source": [
        "%pip install matplotlib numpy opencv-python scipy statsmodels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jy6KCS1zFWqy"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.stats import binom, chi2, expon, kstest, norm, poisson\n",
        "from statsmodels.sandbox.stats.runs import runstest_1samp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cac5pBBcFWq0"
      },
      "source": [
        "## 1. Probability Foundations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toLmUFxRFWq1"
      },
      "source": [
        "### 1.1 Pseudo-Randomness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CC9FGdpFWq2"
      },
      "source": [
        "#### 1.1.1 Linear Congruential Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oNOLq-ZFWq3"
      },
      "source": [
        "Adapted from [The Art of Computer Programming: Seminumerical Algorithms](https://www.amazon.in/Art-Computer-Programming-Seminumerical-Algorithms-ebook/dp/B01AY4ZHKE) (Chapter 3)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UU7wuZ0jFWq4"
      },
      "outputs": [],
      "source": [
        "# Generator\n",
        "def lcg(n, m = 10, a = 7, c = 7, seed = 7):\n",
        "    x = seed\n",
        "    sequence = []\n",
        "    for _ in range(n):\n",
        "        x = (a * x + c) % m\n",
        "        sequence.append(x)\n",
        "    return sequence\n",
        "\n",
        "# Sequence\n",
        "sequence = lcg(10)\n",
        "plt.hist(sequence, bins=10)\n",
        "plt.title(\"Histogram of LCG Sequence\")\n",
        "plt.xlabel(\"Value\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n",
        "\n",
        "# 1. Runs Test\n",
        "runs_test_statistic, runs_test_p_value = runstest_1samp(sequence)\n",
        "print(f\"Runs Test - Statistic: {runs_test_statistic}, P-value: {runs_test_p_value}, Passed: {runs_test_p_value >= 0.05}\")\n",
        "\n",
        "# 2. Chi-Square Test\n",
        "observed_frequencies = np.histogram(sequence, bins=10, range=(0, 9))[0].astype(float)\n",
        "expected_frequencies = np.full_like(observed_frequencies, len(sequence) / 10)\n",
        "chi_square_statistic = np.sum((observed_frequencies - expected_frequencies)**2 / expected_frequencies)\n",
        "chi_square_p_value = 1 - chi2.cdf(chi_square_statistic, df=9)\n",
        "print(f\"Chi-Square Test - Statistic: {chi_square_statistic}, P-value: {chi_square_p_value}, Passed: {chi_square_p_value >= 0.05}\")\n",
        "\n",
        "# 3. Kolmogorov-Smirnov Test\n",
        "ks_statistic, ks_p_value = kstest(sequence, 'uniform')\n",
        "print(f\"Kolmogorov-Smirnov Test - Statistic: {ks_statistic}, P-value: {ks_p_value}, Passed: {ks_p_value >= 0.05}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX-DjT46FWq7"
      },
      "source": [
        "#### 1.1.2 Appreciating XOR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXRULdL9FWq8"
      },
      "source": [
        "Adapted from [Khan Academy](https://www.khanacademy.org/computing/computer-science/cryptography/ciphers/a/xor-and-the-one-time-pad)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k95gooI1FWq8"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread('figures/babbage.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "random_bits = np.random.randint(0, 256, image.shape, dtype=np.uint8)\n",
        "and_result = cv2.bitwise_and(image, random_bits)\n",
        "or_result = cv2.bitwise_or(image, random_bits)\n",
        "xor_result = cv2.bitwise_xor(image, random_bits)\n",
        "\n",
        "fig = plt.figure(figsize=(15, 3))\n",
        "fig.suptitle('Effect of different bitwise operations on an image')\n",
        "\n",
        "plt.subplot(1, 5, 1)\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.title('Image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 5, 2)\n",
        "plt.imshow(random_bits, cmap='gray')\n",
        "plt.title('Noise = U[0, 255]')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 5, 3)\n",
        "plt.imshow(and_result, cmap='gray')\n",
        "plt.title('AND(Image, Noise)')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 5, 4)\n",
        "plt.imshow(or_result, cmap='gray')\n",
        "plt.title('OR(Image, Noise)')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 5, 5)\n",
        "plt.imshow(xor_result, cmap='gray')\n",
        "plt.title('XOR(Image, Noise)')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5M15KiXFWq-"
      },
      "source": [
        "### 1.2 Useful Inequalities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPoCu_vUFWq-"
      },
      "source": [
        "#### 1.2.1 Markov's Inequality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bg6BSRXmFWq_"
      },
      "outputs": [],
      "source": [
        "def markov_bound(mean, a):\n",
        "    return mean / a\n",
        "\n",
        "def binomial_actual_prob(n, p, a):\n",
        "    return 1 - binom.cdf(a, n, p)\n",
        "\n",
        "def exponential_actual_prob(scale, a):\n",
        "    return 1 - expon.cdf(a, scale=scale)\n",
        "\n",
        "def poisson_actual_prob(mu, a):\n",
        "    return 1 - poisson.cdf(a, mu)\n",
        "\n",
        "n = 50\n",
        "p = 0.1\n",
        "scale = 2.0\n",
        "mu = 3.0\n",
        "\n",
        "a_values = np.linspace(1, 20, 100)\n",
        "\n",
        "binomial_bounds = [markov_bound(n * p, a) for a in a_values]\n",
        "binomial_actual = [binomial_actual_prob(n, p, a) for a in a_values]\n",
        "\n",
        "exponential_bounds = [markov_bound(scale, a) for a in a_values]\n",
        "exponential_actual = [exponential_actual_prob(scale, a) for a in a_values]\n",
        "\n",
        "poisson_bounds = [markov_bound(mu, a) for a in a_values]\n",
        "poisson_actual = [poisson_actual_prob(mu, a) for a in a_values]\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
        "fig.suptitle('Comparision of Markov bounds against probabilities computed using CDF')\n",
        "\n",
        "axs[0].plot(a_values, binomial_bounds, label='Markov Bound', color='red')\n",
        "axs[0].plot(a_values, binomial_actual, label='Actual Probability', color='blue')\n",
        "axs[0].set_title('Binomial Distribution')\n",
        "axs[0].set_xlabel('a')\n",
        "axs[0].set_ylabel('Probability')\n",
        "axs[0].legend()\n",
        "axs[0].grid()\n",
        "\n",
        "axs[1].plot(a_values, exponential_bounds, label='Markov Bound', color='red')\n",
        "axs[1].plot(a_values, exponential_actual, label='Actual Probability', color='blue')\n",
        "axs[1].set_title('Exponential Distribution')\n",
        "axs[1].set_xlabel('a')\n",
        "axs[1].set_ylabel('Probability')\n",
        "axs[1].legend()\n",
        "axs[1].grid()\n",
        "\n",
        "axs[2].plot(a_values, poisson_bounds, label='Markov Bound', color='red')\n",
        "axs[2].plot(a_values, poisson_actual, label='Actual Probability', color='blue')\n",
        "axs[2].set_title('Poisson Distribution')\n",
        "axs[2].set_xlabel('a')\n",
        "axs[2].set_ylabel('Probability')\n",
        "axs[2].legend()\n",
        "axs[2].grid()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m144YJRiFWrA"
      },
      "source": [
        "#### 1.2.2 Chebyshev's Inequality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wvSJuiZFWrA"
      },
      "outputs": [],
      "source": [
        "def gaussian_actual_probs(k):\n",
        "    return 2 * (1 - norm.cdf(k))\n",
        "\n",
        "def exponential_actual_probs(k):\n",
        "    prob = np.zeros_like(k)\n",
        "    mask = k < 1\n",
        "    prob[mask] = (1 - np.exp(-(1 - k[mask]))) + np.exp(-(1 + k[mask]))\n",
        "    prob[~mask] = np.exp(-(1 + k[~mask]))\n",
        "    return prob\n",
        "\n",
        "def uniform_actual_probs(k):\n",
        "    return np.where(k <= np.sqrt(3), 1 - (k / np.sqrt(3)), 0)\n",
        "\n",
        "k_values = np.linspace(1, 3, 100)\n",
        "chebyshev_bounds = 1 / (k_values**2)\n",
        "\n",
        "gaussian_probs = gaussian_actual_probs(k_values)\n",
        "exponential_probs = exponential_actual_probs(k_values)\n",
        "uniform_probs = uniform_actual_probs(k_values)\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
        "fig.suptitle('Comparision of Chebyshev bounds against probabilities computed using CDF')\n",
        "\n",
        "axs[0].plot(k_values, chebyshev_bounds, label='Chebyshev Bound', color='blue')\n",
        "axs[0].plot(k_values, gaussian_probs, label='Actual Probability (Gaussian)', color='red')\n",
        "axs[0].set_xlabel('k')\n",
        "axs[0].set_ylabel('Probability')\n",
        "axs[0].set_title('Gaussian Distribution')\n",
        "axs[0].legend()\n",
        "axs[0].grid(True)\n",
        "\n",
        "axs[1].plot(k_values, chebyshev_bounds, label='Chebyshev Bound', color='blue')\n",
        "axs[1].plot(k_values, exponential_probs, label='Actual Probability (Exponential)', color='green')\n",
        "axs[1].set_xlabel('k')\n",
        "axs[1].set_ylabel('Probability')\n",
        "axs[1].set_title('Exponential Distribution')\n",
        "axs[1].legend()\n",
        "axs[1].grid(True)\n",
        "\n",
        "axs[2].plot(k_values, chebyshev_bounds, label='Chebyshev Bound', color='blue')\n",
        "axs[2].plot(k_values, uniform_probs, label='Actual Probability (Uniform)', color='purple')\n",
        "axs[2].set_xlabel('k')\n",
        "axs[2].set_ylabel('Probability')\n",
        "axs[2].set_title('Uniform Distribution')\n",
        "axs[2].legend()\n",
        "axs[2].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Adjmnb-1FWrA"
      },
      "source": [
        "## 2. Probability Distributions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpM-K3iHFWrA"
      },
      "source": [
        "### 2.1 Discrete Probability Distributions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Mgo0n4EFWrB"
      },
      "source": [
        "1. Visit https://www.desmos.com/calculator/gyl3z0aptn\n",
        "\n",
        "2. Open the groups corresponding to different distributions in the sidebar.\n",
        "\n",
        "3. Toggle the distributions you want to visualize.\n",
        "\n",
        "4. Change the parameters of the distribution, initialized in the last group."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nM0fgWPNFWrB"
      },
      "source": [
        "### 2.2 Continuous Probability Distributions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEGFw48PFWrB"
      },
      "source": [
        "1. Visit https://www.desmos.com/calculator/vwxz5ldzov\n",
        "\n",
        "2. Open the groups corresponding to different distributions in the sidebar.\n",
        "\n",
        "3. Toggle the distributions you want to visualize."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oujBEBd5FWrB"
      },
      "source": [
        "### 2.3 Sampling from Distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8N57p_OFWrB"
      },
      "outputs": [],
      "source": [
        "def inverse_transform_exponential(size, rate=1.0):\n",
        "    u = np.random.uniform(0, 1, size)\n",
        "    return -np.log(1 - u) / rate\n",
        "\n",
        "def box_muller_normal(size):\n",
        "    u1 = np.random.uniform(0, 1, size // 2)\n",
        "    u2 = np.random.uniform(0, 1, size // 2)\n",
        "    z0 = np.sqrt(-2 * np.log(u1)) * np.cos(2 * np.pi * u2)\n",
        "    z1 = np.sqrt(-2 * np.log(u1)) * np.sin(2 * np.pi * u2)\n",
        "    return np.concatenate([z0, z1])\n",
        "\n",
        "def acceptance_rejection_poisson(size, lambda_poisson):\n",
        "    samples = []\n",
        "    n = 100\n",
        "    p = lambda_poisson / n\n",
        "    while len(samples) < size:\n",
        "        u = np.random.uniform(0, 1)\n",
        "        y = np.random.binomial(n, p)\n",
        "        if u <= (poisson.pmf(y, lambda_poisson) / binom.pmf(y, n, p)):\n",
        "            samples.append(y)\n",
        "    return np.array(samples)\n",
        "\n",
        "num_samples = 10000\n",
        "lambda_poisson = 5\n",
        "\n",
        "exp_samples = inverse_transform_exponential(num_samples)\n",
        "normal_samples = box_muller_normal(num_samples)\n",
        "poisson_samples = acceptance_rejection_poisson(num_samples, lambda_poisson)\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "fig.suptitle('Histogram (normalized) of generated samples against actual distribution')\n",
        "\n",
        "x = np.linspace(0, 10, 1000)\n",
        "axs[0].hist(exp_samples, bins=50, density=True, color='blue', alpha=0.7)\n",
        "axs[0].plot(x, expon.pdf(x), color='red', label='Exponential PDF')\n",
        "axs[0].set_title('Exponential Samples (Inverse Transform)')\n",
        "axs[0].legend()\n",
        "\n",
        "x = np.linspace(-4, 4, 1000)\n",
        "axs[1].hist(normal_samples, bins=50, density=True, color='green', alpha=0.7)\n",
        "axs[1].plot(x, norm.pdf(x), color='red', label='Normal PDF')\n",
        "axs[1].set_title('Normal Samples (Box Muller)')\n",
        "axs[1].legend()\n",
        "\n",
        "x = np.arange(0, 20)\n",
        "axs[2].hist(poisson_samples, bins=range(0, 20), density=True, color='orange', alpha=0.7, align='left')\n",
        "axs[2].plot(x, poisson.pmf(x, lambda_poisson), 'ro-', label='Poisson PMF')\n",
        "axs[2].set_title('Poisson Samples (Rejection Sampling)')\n",
        "axs[2].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "ks_exp = kstest(exp_samples, 'expon')\n",
        "print(f\"KS Test for Exponential Samples: Statistic={ks_exp.statistic}, p-value={ks_exp.pvalue}, Passed: {ks_exp.pvalue >= 0.05}\")\n",
        "\n",
        "ks_norm = kstest(normal_samples, 'norm')\n",
        "print(f\"KS Test for Normal Samples: Statistic={ks_norm.statistic}, p-value={ks_norm.pvalue}, Passed: {ks_norm.pvalue >= 0.05}\")\n",
        "\n",
        "ks_poisson = kstest(poisson_samples, 'poisson', args=(lambda_poisson, 0))\n",
        "print(f\"KS Test for Poisson Samples: Statistic={ks_poisson.statistic}, p-value={ks_poisson.pvalue}, Passed: {ks_poisson.pvalue >= 0.05}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl87zZ5qFWrD"
      },
      "source": [
        "## 3. Stochastic Processes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDKXnsY4FWrD"
      },
      "source": [
        "### 3.1 Markov Chains"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNbSIM74FWrE"
      },
      "source": [
        "#### 3.1.1 Limiting Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jo8pkoo-FWrE"
      },
      "outputs": [],
      "source": [
        "P = np.array([\n",
        "    [0.5, 0.3, 0.2],\n",
        "    [0.2, 0.6, 0.2],\n",
        "    [0.3, 0.3, 0.4]\n",
        "])\n",
        "initial_dist = np.array([1.0, 0.0, 0.0])\n",
        "print(f\"Initial Distribution: {initial_dist}\")\n",
        "\n",
        "num_steps = 15\n",
        "curr_dist = initial_dist\n",
        "for i in range(num_steps):\n",
        "    curr_dist = curr_dist @ P\n",
        "    print(f\"Step {i + 1}: {curr_dist}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3thf0wIjFWrF"
      },
      "source": [
        "#### 3.1.2 BONUS: Queueing Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIyVXiKiFWrF"
      },
      "source": [
        "Look at Jackson Network which is modeled using a stationary routing matrix: https://en.wikipedia.org/wiki/Jackson_network.\n",
        "\n",
        "You can look at the slides and Python simulation here: https://github.com/ihsingh2/open-queueing-networks/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at3zXjflFWrG"
      },
      "source": [
        "### 3.2 Convergence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtk8Xm8HFWrG"
      },
      "source": [
        "#### 3.2.1 Law of Large Numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Vh-n9eNFWrG"
      },
      "outputs": [],
      "source": [
        "def running_average(data):\n",
        "    return np.cumsum(data) / np.arange(1, len(data) + 1)\n",
        "\n",
        "seq_len = 800\n",
        "\n",
        "n = 50\n",
        "p = 0.5\n",
        "lambda_ = 5\n",
        "\n",
        "binomial_samples = np.random.binomial(n, p, seq_len)\n",
        "geometric_samples = np.random.geometric(p, seq_len)\n",
        "poisson_samples = np.random.poisson(lambda_, seq_len)\n",
        "\n",
        "binomial_running_avg = running_average(binomial_samples)\n",
        "geometric_running_avg = running_average(geometric_samples)\n",
        "poisson_running_avg = running_average(poisson_samples)\n",
        "\n",
        "binomial_expected = n * p\n",
        "geometric_expected = 1 / p\n",
        "poisson_expected = lambda_\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(16, 4))\n",
        "fig.suptitle('Convergence of sample mean with increasing sample size')\n",
        "\n",
        "axs[0].plot(binomial_running_avg)\n",
        "axs[0].axhline(binomial_expected, color='r', linestyle='--')\n",
        "axs[0].set_title('Binomial Distribution')\n",
        "\n",
        "axs[1].plot(geometric_running_avg)\n",
        "axs[1].axhline(geometric_expected, color='r', linestyle='--')\n",
        "axs[1].set_title('Geometric Distribution')\n",
        "\n",
        "axs[2].plot(poisson_running_avg)\n",
        "axs[2].axhline(poisson_expected, color='r', linestyle='--')\n",
        "axs[2].set_title('Poisson Distribution')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-W5yXiYFWrH"
      },
      "source": [
        "#### 3.2.2 Central Limit Theorem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoEhU3exFWrI"
      },
      "outputs": [],
      "source": [
        "def normalize_means(means, population_mean, population_std):\n",
        "    return (means - population_mean) / (population_std / np.sqrt(len(means)))\n",
        "\n",
        "num_samples = 1000\n",
        "sample_size = 1000\n",
        "\n",
        "n = 50\n",
        "p = 0.5\n",
        "lambda_ = 5\n",
        "\n",
        "binomial_samples = np.random.binomial(n, p, (num_samples, sample_size))\n",
        "geometric_samples = np.random.geometric(p, (num_samples, sample_size))\n",
        "poisson_samples = np.random.poisson(lambda_, (num_samples, sample_size))\n",
        "\n",
        "binomial_means = np.mean(binomial_samples, axis=1)\n",
        "geometric_means = np.mean(geometric_samples, axis=1)\n",
        "poisson_means = np.mean(poisson_samples, axis=1)\n",
        "\n",
        "binomial_normalized = normalize_means(binomial_means, n * p, np.sqrt(n * p * (1 - p)))\n",
        "geometric_normalized = normalize_means(geometric_means, 1 / p, np.sqrt((1 - p) / p**2))\n",
        "poisson_normalized = normalize_means(poisson_means, lambda_, np.sqrt(lambda_))\n",
        "\n",
        "x = np.linspace(-4, 4, 1000)\n",
        "standard_normal = norm.pdf(x, 0, 1)\n",
        "hist_range = (-4, 4)\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "fig.suptitle('Convergence of normalized distribution to standard normal')\n",
        "\n",
        "axs[0].hist(binomial_normalized, bins=30, density=True, alpha=0.6, range=hist_range, label='Normalized Means')\n",
        "axs[0].plot(x, standard_normal, 'r', label='Standard Normal')\n",
        "axs[0].set_title('Binomial Distribution')\n",
        "axs[0].legend()\n",
        "\n",
        "axs[1].hist(geometric_normalized, bins=30, density=True, alpha=0.6, range=hist_range, label='Normalized Means')\n",
        "axs[1].plot(x, standard_normal, 'r', label='Standard Normal')\n",
        "axs[1].set_title('Geometric Distribution')\n",
        "axs[1].legend()\n",
        "\n",
        "axs[2].hist(poisson_normalized, bins=30, density=True, alpha=0.6, range=hist_range, label='Normalized Means')\n",
        "axs[2].plot(x, standard_normal, 'r', label='Standard Normal')\n",
        "axs[2].set_title('Poisson Distribution')\n",
        "axs[2].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQQPEpJMFWrI"
      },
      "source": [
        "## 4. References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9W0Q9f3pFWrJ"
      },
      "source": [
        "1. Introduction to Probability, Statistics and Random Processes: https://probabilitycourse.com/\n",
        "\n",
        "2. The Book of Statistical Proofs: https://statproofbook.github.io/I/ToC\n",
        "\n",
        "3. The Art of Computer Programming (Volume 2, Chapter 3): https://www.amazon.in/Art-Computer-Programming-Seminumerical-Algorithms-ebook/dp/B01AY4ZHKE"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "iiit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}